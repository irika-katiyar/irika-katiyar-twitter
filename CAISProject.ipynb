{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irika-katiyar/irika-katiyar-twitter/blob/main/CAISProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports / mounting to dive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/CAIS Project"
      ],
      "metadata": {
        "id": "PNiY90sR5F09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f40110-84cd-4949-8ce3-e88021b2e117"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/CAIS Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xADTr5_Hfe_n",
        "outputId": "00068967-a148-4a7b-803c-2456261454df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGbJv5-ooeTB",
        "outputId": "4608e521-167f-4e3f-d18f-f05d14700add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Setting tweets and labels to columns of df\n",
            "2: tokenizing tweets\n",
            "3: padding\n",
            "4: loading word embeddings\n",
            "5: finding word embeddings\n"
          ]
        }
      ],
      "source": [
        "#df = pd.read_csv(\"/content/drive/My Drive/CAIS Project/dataset/data.csv\", header=0, skiprows=[i for i in range(1,795000)], nrows=10000)\n",
        "df = pd.read_csv(\"/content/drive/My Drive/CAIS Project/dataset/data-small.csv\", header=0)\n",
        "\n",
        "#using GloVe file from Lesson 6 RNN example to avoid having to download and put into my Google Drive\n",
        "EMBEDDINGS_DIR = '/content/drive/My Drive/2021 Fall Curriculum/Lessons/Lesson 6: RNNs/glove.6B.50d.txt'\n",
        "\n",
        "#data preprocessing using method similar to Lesson 6 RNN example\n",
        "%run -i load_data.py\n",
        "tweets, tweets_preprocessed, labels, word_index, embedding_matrix = load_data(df, EMBEDDINGS_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing what training data looks like\n",
        "print(\"Training Data Size: \", tweets_preprocessed.shape)\n",
        "print(\"Number of Tweets: \", tweets_preprocessed.shape[0])\n",
        "print(\"Max Tweet Length: \", tweets_preprocessed.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ph7CcNMvNnj",
        "outputId": "fc37aa3d-2e98-405b-b43a-7495f0d02bb4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Size:  (268012, 46)\n",
            "Number of Tweets:  268012\n",
            "Max Tweet Length:  46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GFIl6GCnnx4r"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Dense, Activation, Flatten\n",
        "from keras.layers import Dropout, concatenate\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras import metrics\n",
        "from keras.models import Model\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating model using 2 LSTM layers and 2 Dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                    output_dim=EMBEDDING_DIM,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=tweets_preprocessed.shape[1],\n",
        "                    trainable=False))\n",
        "model.add(LSTM(64, return_sequences = True, activation='relu'))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'RMSprop', metrics=[metrics.binary_accuracy])"
      ],
      "metadata": {
        "id": "DIxW7x--4iTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9258ba2-93a8-49f4-f6b7-327c2d1c7029"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 46, 50)            9794000   \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 46, 64)            29440     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 46, 64)            0         \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 64)                33024     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,858,577\n",
            "Trainable params: 64,577\n",
            "Non-trainable params: 9,794,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-cf4aVwY0aX",
        "outputId": "34cf7a8f-5414-4c65-b5cc-3cdeda0b1e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1047/1047 [==============================] - 208s 194ms/step - loss: 0.2322 - binary_accuracy: 0.8422 - val_loss: -39.5953 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "1047/1047 [==============================] - 202s 193ms/step - loss: 7232.5728 - binary_accuracy: 0.7891 - val_loss: 8.5078 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "1047/1047 [==============================] - 203s 194ms/step - loss: 34427.7227 - binary_accuracy: 0.7868 - val_loss: -74.4831 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "1047/1047 [==============================] - 203s 194ms/step - loss: 10071.4160 - binary_accuracy: 0.7357 - val_loss: -139.0674 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "1047/1047 [==============================] - 203s 194ms/step - loss: 0.3704 - binary_accuracy: 0.7107 - val_loss: -571.0383 - val_binary_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ccc579990>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "TEST_SIZE = 0.5\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 128\n",
        "#training and testing model\n",
        "model.fit(tweets_preprocessed, labels, \n",
        "          epochs = EPOCHS, \n",
        "          batch_size = BATCH_SIZE, \n",
        "          validation_split =TEST_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trying to see what the model outputs for different tweets\n",
        "for x in range(4990,5010):\n",
        "  tweet_ex = np.array([tweets_preprocessed[x]])\n",
        "  value = model.predict(tweet_ex)\n",
        "  print(value[0])\n",
        "  print (labels[x])"
      ],
      "metadata": {
        "id": "Iwb-Wv4my5Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ed632f-2191-4327-eae4-d1695f91c273"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.]\n",
            "0\n",
            "[0.]\n",
            "0\n",
            "[0.]\n",
            "0\n",
            "[2.184199e-24]\n",
            "0\n",
            "[0.]\n",
            "0\n",
            "[0.]\n",
            "0\n",
            "[0.]\n",
            "0\n",
            "[5.8406654e-19]\n",
            "0\n",
            "[3.4593678e-36]\n",
            "0\n",
            "[0.]\n",
            "0\n",
            "[0.]\n",
            "0\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "4\n",
            "[8.380916e-38]\n",
            "4\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CAISProject.ipynb",
      "provenance": [],
      "mount_file_id": "1CzA8svKPqOlzqubbXS7Cw3i7DKGwmN-N",
      "authorship_tag": "ABX9TyM8d7dpsJJ1Iv50zScZr1P5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}