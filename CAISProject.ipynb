{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irika-katiyar/irika-katiyar-twitter/blob/main/CAISProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BD3xEY7qC95"
      },
      "source": [
        "installing necessary libraries and mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/CAIS Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNiY90sR5F09",
        "outputId": "736de380-e57f-4ec4-e89f-7c85813e994b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/CAIS Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xADTr5_Hfe_n",
        "outputId": "176c9559-d602-4b31-83b9-01a46688d57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCzp2vkep8v9"
      },
      "source": [
        "Reading in the csv file and making it into a data frame + tweet preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGbJv5-ooeTB",
        "outputId": "6de29a23-ccb4-4bad-c7a9-2ac35482d3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Setting tweets and labels to columns of df\n",
            "2: tokenizing tweets\n",
            "3: padding\n",
            "4: loading word embeddings\n",
            "5: finding word embeddings\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/CAIS Project/dataset/data.csv\", header=0)\n",
        " \n",
        "EMBEDDINGS_DIR = '/content/drive/My Drive/2021 Fall Curriculum/Lessons/Lesson 6: RNNs/glove.6B.50d.txt'\n",
        "\n",
        "%run -i load_data.py\n",
        "tweets, tweets_preprocessed, labels, word_index, embedding_matrix = load_data(df, EMBEDDINGS_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg1IR0tDnsd8"
      },
      "source": [
        "checking embedding matrix for word america"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN00q_ywkD4e",
        "outputId": "50bafaa0-0e1e-4d51-c336-6bf70cf1c945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "america has a word index of:  1740\n",
            "\n",
            "america has a word embedding of:\n",
            " [-0.13124     0.46555001 -0.10921     0.18759     0.073319   -0.40072\n",
            " -1.14180005 -0.52591997  0.20455     0.22532     0.19891     0.21863\n",
            " -0.14053001  0.026534    0.35482001 -0.27559    -0.14432999  0.14207999\n",
            " -0.23811001 -0.0045941  -0.14462    -0.10607    -0.23974     0.44398999\n",
            " -0.033788   -1.77400005 -0.97387999 -0.33886999  0.29912999 -0.21471\n",
            "  2.93460011  0.47296    -0.069746   -0.42936999 -1.02279997 -1.10210001\n",
            " -1.14900005 -0.39353001 -0.46068001 -0.63748002 -0.38899001 -0.50265998\n",
            "  0.92110002 -0.40483001 -0.19845     0.94019997 -0.59245998 -0.33818001\n",
            " -0.54872     0.41817999]\n"
          ]
        }
      ],
      "source": [
        "word = \"america\"\n",
        "\n",
        "idx = word_index[word]\n",
        "\n",
        "embedding = embedding_matrix[idx]\n",
        "\n",
        "print(word, \"has a word index of: \", idx) \n",
        "print()\n",
        "print(word, \"has a word embedding of:\\n\", embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "GFIl6GCnnx4r"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Dense, Activation, Flatten\n",
        "from keras.layers import Dropout, concatenate\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras import metrics\n",
        "from keras.models import Model\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(word_index) + 1,\n",
        "                    output_dim=EMBEDDING_DIM,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=tweets_preprocessed.shape[1]))\n",
        "model.add(LSTM(EMBEDDING_DIM, return_sequences = True, activation='relu'))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(LSTM(EMBEDDING_DIM, activation='relu'))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'RMSprop', metrics = [metrics.accuracy])"
      ],
      "metadata": {
        "id": "DIxW7x--4iTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72333e49-3c73-4416-ed9b-64b1be6b8ab2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 118, 50)           34548050  \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 118, 50)           20200     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 118, 50)           0         \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 50)                20200     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 50)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 32)                1632      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,590,115\n",
            "Trainable params: 34,590,115\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-cf4aVwY0aX",
        "outputId": "7f4e9c9d-a012-4a07-ea05-28f64b89d183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "11082/25000 [============>.................] - ETA: 1:08:24 - loss: 0.0000e+00 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "TEST_SIZE = 0.5\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "model.fit(tweets_preprocessed, labels, \n",
        "          epochs = EPOCHS, \n",
        "          batch_size = BATCH_SIZE, \n",
        "          validation_split =TEST_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(800000, 800100):\n",
        "  tweet_ex = np.array([tweets_preprocessed[x]])\n",
        "  value = model.predict(tweet_ex)\n",
        "  print(value[0])\n",
        "  print (labels[x])"
      ],
      "metadata": {
        "id": "Iwb-Wv4my5Vs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CAISProject.ipynb",
      "provenance": [],
      "mount_file_id": "1CzA8svKPqOlzqubbXS7Cw3i7DKGwmN-N",
      "authorship_tag": "ABX9TyPJJFJ6mtIBI7UKRKgPk6SP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}